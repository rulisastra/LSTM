{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membaca data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv ('data.csv',\n",
    "                    usecols=[3],\n",
    "                    engine='python',\n",
    "                    delimiter= \",\",\n",
    "                    thousands=\",\"))\n",
    "data = data.values\n",
    "data = data.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pemisahan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = data\n",
    "windowSize = 5\n",
    "def splitData(x, windowSize, a, b, c):\n",
    "    if ((a+b+c) != 1):\n",
    "        print(\"pemisahan tidak valid\")\n",
    "    else:\n",
    "        train = []\n",
    "        vald = []\n",
    "        test = []\n",
    "        train_size = int(len(x)*a)\n",
    "        val_size = int(len(x)*b)\n",
    "        test_size = len(x) - train_size - val_size\n",
    "        train = x[0:train_size-1,:]\n",
    "        vald = x[train_size-windowSize-\n",
    "                1:train_size+val_size-1]\n",
    "        test = x[train_size+val_size-windowSize-\n",
    "                1:len(x),:]\n",
    "        print(len(train), len(vald), len(test))\n",
    "    return np.array(train), np.array(vald), np.array(test)\n",
    "\n",
    "train, vald, test = splitData(x, windowSize, 0.6, 0.15, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normalize(x,scale):\n",
    "    normalized = []\n",
    "    for i in range(len(x)) :\n",
    "        a = (min(scale))+(x[i]-min(x))\n",
    "                *(max(scale)-min(scale))/(max(x)-min(x))\n",
    "        normalized.append(a)\n",
    "    return np.array(normalized)\n",
    "scale = (-1,1)\n",
    "normalized = normalize(data,scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pembuatan dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(x, windowSize):\n",
    "    dataX, dataY = [],[]\n",
    "    for i in range(len(x)-windowSize):\n",
    "        a = []\n",
    "        for j in range(i, i+windowSize):\n",
    "            for k in range(len(x[j])):\n",
    "                a.append(x[j,k]);        \n",
    "        dataX.append(a)\n",
    "        dataY.append(x[i+windowSize,0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = createDataset(train,windowSize)\n",
    "valdX, valdY = createDataset(vald, windowSize)\n",
    "testX, testY = createDataset(test, windowSize)\n",
    "\n",
    "trainY = np.reshape(trainY,(len(trainY), 1))\n",
    "valdY = np.reshape(valdY,(len(valdY), 1))\n",
    "testY = np.reshape(testY,(len(testY), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analisis Univariat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memilih data latih, validasi, dan uji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNorm = normalize(train, scale)\n",
    "valNorm = normalize(vald, scale)\n",
    "testNorm = normalize(test, scale)\n",
    "\n",
    "latih = trainNorm\n",
    "valid = valNorm\n",
    "uji = testNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis mulivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingAverage(x,n):\n",
    "    MA = []\n",
    "    for i in range(len(x)-n+1):\n",
    "        a = np.mean(x[i:i+n,])\n",
    "        MA.append(a)\n",
    "    return np.arrat(MA)\n",
    "\n",
    "maSize = 1\n",
    "\n",
    "maTrain = movingAverage(train,maSize)\n",
    "maVal = movingAverage(vald,maSize)\n",
    "maTest = movingAverage(tes,maSize)\n",
    "\n",
    "def createMA(x,y, maSize):\n",
    "    y = np.reshape(y, (len(y), 1))\n",
    "    dataAndNormalized = x[(maSize)-1:len(x)]\n",
    "    combined = np.concatenate(((dataandNormalized), (y)), \n",
    "                             axis=1)\n",
    "    returned combined\n",
    "\n",
    "maTrainNorm = normalize(maTrain, scale)\n",
    "maValNorm = normalize(maVal, scale)\n",
    "maTestNorm = normalize(maTest, scale)\n",
    "\n",
    "latih = createMA(trainNorm, maTrainNorm, maSize)\n",
    "valid = createMA(valNorm, maValNorm, maSize)\n",
    "uji = createMA(testNorm, maTestNorm, maSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masukan 2 nilai tukar mata uang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data\n",
    "x2 = data2\n",
    "\n",
    "train, vald, test = splitData(x, windowSize, 0.6, 0.15, 0.25)\n",
    "train2, vald2, test2 = splitData(x2, windowSize, 0.6, 0.15, 0.25)\n",
    "\n",
    "trainNorm = normalize(train, scale)\n",
    "valNorm = normalize(vald, scale)\n",
    "testNorm = normalize(test, scale)\n",
    "\n",
    "train2norm = normalize(train2, scale)\n",
    "val2norm = normalize(vald2, scale)\n",
    "test2norm = normalize(test2, scale)\n",
    "\n",
    "latih = np. concatenate(((trainNorm), (train2norm)), axis=1)\n",
    "valid = np. concatenate(((valNorm), (val2norm)), axis=1)\n",
    "uji = np. concatenate(((testNorm), (test2norm)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTASI JST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateBobot(x):\n",
    "    x[0:len(x)-1]=x[0:len(x)-1]*0.\n",
    "    x[-1]=1.\n",
    "    return x\n",
    "\n",
    "savedLoss = []\n",
    "neuron = 1\n",
    "nmb_epoch =100\n",
    "start_time = time.time()\n",
    "np.random.seed(15)\n",
    "model = Sequential()\n",
    "model.add(LSTM(neuron,\n",
    "              input_dim=windowSize*len(latih.transpose())))\n",
    "lapisan = Dense(1, trainable=False)\n",
    "model.add(lapisan)\n",
    "filepath=\"bobot\\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=2, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "model.compile(loss='mse', optimizer='RMSprop', stateful=True)\n",
    "oldBobot = model.get_weights()\n",
    "updateBobot(oldBobot[3])\n",
    "model.set_weights(oldBobot)\n",
    "hist = model.fit(trainX, trainY, nb_epoch=nmb_epoch,\n",
    "                batch_size=1, verbose=1, callbacks=callbacks_list,\n",
    "                validation_data=(valdX, valdY))\n",
    "hist\n",
    "savedLoss[] = hist.history\n",
    "print (\"training\", neuron, \"done in\")\n",
    "\n",
    "savedLoss[] = hist.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penerapan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(testX)\n",
    "valPredict = model.predict(valdX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(x, source, scale):\n",
    "    denormalized = []\n",
    "    fro i in range(len(x)):\n",
    "        a - ((x[i]-min(scale))*(max(source)-min(source)))/\n",
    "        (max(scale))+min(source)\n",
    "        denormalized.append(a)\n",
    "    return np.array(denormalized)\n",
    "\n",
    "denormTestPredict = denormalize(testPredict, test, scale)\n",
    "denormValPredict = denormalize(valPredict, vald, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pengujian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "membuat tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLabel = denormalized(testY, test, scale)\n",
    "valLabel = denormalized(valY, vald, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(x,y):\n",
    "    mae = []\n",
    "    for i in range(len(x)):\n",
    "        a = abs(x[i]-y[i])\n",
    "        mae.append(a)\n",
    "    return float((sum(mse))/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y):\n",
    "    rmse = []\n",
    "    for i in range(len(x)):\n",
    "        a = (x[i]-y[i])**2\n",
    "        mse.append(a)\n",
    "return float((sum(mse)/len(y))**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(x,y):\n",
    "    mape = []\n",
    "    for i in range(len(y)):\n",
    "        a = abs(y[i]-x[i])/y[i]\n",
    "        mape.append(a)\n",
    "    return float(sum(mape)/len(y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dstat(x,y):\n",
    "    dstat = 0\n",
    "    n = len(y)\n",
    "    for i in range(n-1):\n",
    "        if(((x[i+1]-y[i])*(y[i+1]-y[i]))>=0):\n",
    "            dstat += 1\n",
    "    Dstat = (1/float(n-2))*float(dstat)*100\n",
    "    return float(Dstat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------Pembahasan----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring[] = (neuron,\n",
    "            mae (denormValPredict, valLabel),\n",
    "            rmse (denormValPredict, valLabel),\n",
    "             mape (denormValPredict, valLabel),\n",
    "             dstat (denormValPredict, valLabel),\n",
    "             mae (denormTestPredict, testLabel),\n",
    "             rmse (denormTestPredict, testLabel),\n",
    "             mape (denormTestPredict, testLabel),\n",
    "             dstat (denormTestPredict, testLabel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
